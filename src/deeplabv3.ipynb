{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "from CamVidData import SemanticSegmentationDataset\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from segdataset import SegmentationDataset\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision import models\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDeepLabv3(outputchannels=32):\n",
    "    \"\"\"DeepLabv3 class with custom head\n",
    "    Args:\n",
    "        outputchannels (int, optional): The number of output channels\n",
    "        in your dataset masks. Defaults to 32.\n",
    "    Returns:\n",
    "        model: Returns the DeepLabv3 model with the ResNet101 backbone.\n",
    "    \"\"\"\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=True,\n",
    "                                                    progress=True)\n",
    "    model.classifier = DeepLabHead(2048, outputchannels)\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, criterion, dataloaders, optimizer, metrics, bpath,\n",
    "                num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    # Use gpu if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    # Initialize the log file for training and testing loss and metrics\n",
    "    fieldnames = ['epoch', 'Train_loss', 'Test_loss'] + \\\n",
    "        [f'Train_{m}' for m in metrics.keys()] + \\\n",
    "        [f'Test_{m}' for m in metrics.keys()]\n",
    "    with open(os.path.join(bpath, 'log.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        # Initialize batch summary\n",
    "        batchsummary = {a: [0] for a in fieldnames}\n",
    "\n",
    "        for phase in ['Train', 'Test']:\n",
    "            if phase == 'Train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            # Iterate over data.\n",
    "            for sample in tqdm(iter(dataloaders[phase])):\n",
    "                inputs = sample['image'].to(device)\n",
    "                masks = sample['mask'].to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'Train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs['out'], masks)\n",
    "                    y_pred = outputs['out'].data.cpu().numpy().ravel()\n",
    "                    y_true = masks.data.cpu().numpy().ravel()\n",
    "                    for name, metric in metrics.items():\n",
    "                        if name == 'f1_score':\n",
    "                            # Use a classification threshold of 0.1\n",
    "                            batchsummary[f'{phase}_{name}'].append(\n",
    "                                metric(y_true > 0, y_pred > 0.1))\n",
    "                        else:\n",
    "                            batchsummary[f'{phase}_{name}'].append(\n",
    "                                metric(y_true.astype('uint8'), y_pred))\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'Train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "            batchsummary['epoch'] = epoch\n",
    "            epoch_loss = loss\n",
    "            batchsummary[f'{phase}_loss'] = epoch_loss.item()\n",
    "            print('{} Loss: {:.4f}'.format(phase, loss))\n",
    "        for field in fieldnames[3:]:\n",
    "            batchsummary[field] = np.mean(batchsummary[field])\n",
    "        print(batchsummary)\n",
    "        with open(os.path.join(bpath, 'log.csv'), 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow(batchsummary)\n",
    "            # deep copy the model\n",
    "            if phase == 'Test' and loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Lowest Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-segmentation-EDnG7sl7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
